{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference NAP and save results to standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, os.path as osp\n",
    "\n",
    "sys.path.append(osp.dirname(os.getcwd()))\n",
    "from core.models import get_model\n",
    "from init import setup_seed\n",
    "import yaml, logging, imageio, torch, os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dataset import get_dataset\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "import trimesh\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "def prepare_nap(nap_version=\"v6.1\", nap_ep=\"5455\"):\n",
    "    # prepare the model\n",
    "    # cfg_fn = f\"../configs/v5/{nap_version}_diffusion.yaml\"\n",
    "    cfg_fn = f\"../configs/nap/{nap_version}_diffusion.yaml\"\n",
    "    ckpt = torch.load(f\"../log/{nap_version}_diffusion/checkpoint/{nap_ep}.pt\")\n",
    "    with open(cfg_fn, \"r\") as f:\n",
    "        cfg = yaml.full_load(f)\n",
    "    cfg[\"logging\"][\"viz_frame\"] = 10\n",
    "    cfg[\"root\"] = osp.dirname(os.getcwd())\n",
    "    cfg[\"modes\"] = [\"train\", \"val\", \"test\"]\n",
    "    cfg[\"dataset\"][\"dataset_proportion\"] = [1.0, 1.0, 1.0]\n",
    "    # handle the dir change\n",
    "    cfg[\"dataset\"][\"split_path\"] = osp.join(\"..\", cfg[\"dataset\"][\"split_path\"])\n",
    "    cfg[\"dataset\"][\"embedding_index_file\"] = osp.join(\"..\", cfg[\"dataset\"][\"embedding_index_file\"])\n",
    "    cfg[\"dataset\"][\"embedding_precompute_path\"] = osp.join(\n",
    "        \"..\", cfg[\"dataset\"][\"embedding_precompute_path\"]\n",
    "    )\n",
    "    cfg[\"model\"][\"part_shape_prior\"][\"pretrained_shapeprior_path\"] = osp.join(\n",
    "        \"..\", cfg[\"model\"][\"part_shape_prior\"][\"pretrained_shapeprior_path\"]\n",
    "    )\n",
    "\n",
    "    ModelClass = get_model(cfg[\"model\"][\"model_name\"])\n",
    "    nap_model = ModelClass(cfg)\n",
    "    nap_model.model_resume(ckpt, is_initialization=True, network_name=[\"all\"])\n",
    "    nap_model.to_gpus()\n",
    "    nap_model.set_eval()\n",
    "    # get the scale factor\n",
    "    dataclass = get_dataset(cfg)\n",
    "    dataset = dataclass(cfg, \"train\")\n",
    "    training_E_scale, training_V_scale = dataset.E_scale.copy(), dataset.V_scale.copy()\n",
    "    training_V_scale = np.concatenate([training_V_scale, dataset.embedding_scale], axis=-1)\n",
    "    training_E_scale = torch.from_numpy(training_E_scale).float().cuda()\n",
    "    training_V_scale = torch.from_numpy(training_V_scale).float().cuda()\n",
    "    training_scale = (training_V_scale, training_E_scale)\n",
    "\n",
    "    database = NearestNeighbors(n_neighbors=1, algorithm=\"ball_tree\").fit(\n",
    "        dataset.training_embedding\n",
    "    )  # it's train embedding\n",
    "    mesh_names = dataset.training_embedding_index\n",
    "    return nap_model, training_scale, database, mesh_names, cfg\n",
    "\n",
    "\n",
    "def gen(model, V_scale, E_scale, N=100):\n",
    "    net = model.network\n",
    "    K = model.K\n",
    "    noise_V = torch.randn(N, K, 1 + 6 + net.shapecode_dim).cuda()\n",
    "    noise_E = torch.randn(N, (K * (K - 1)) // 2, 13).cuda()\n",
    "    V, E = net.generate(noise_V, noise_E, V_scale, E_scale)\n",
    "    # if net.use_hard_v_mask:\n",
    "    #     random_n = torch.randint(low=2, high=K + 1, size=(N,))\n",
    "    #     V_mask = torch.arange(K)[None, :] < random_n[:, None]\n",
    "    #     V_mask = V_mask.float().to(noise_V.device)\n",
    "    #     noise_V[..., 0] = V_mask  # set the noisy first channel to gt v_mask\n",
    "    # else:\n",
    "    #     V_mask = None\n",
    "    # V, E = net.generate(noise_V, noise_E, V_scale, E_scale, V_mask=V_mask)\n",
    "    return V, E, noise_V, noise_E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(12345)\n",
    "VERSION, EP = \"v6.1\", \"5455\"\n",
    "# VERSION, EP = \"v5.1.5\", \"5455\"\n",
    "# VERSION, EP = \"v5.1.6\", \"5455\"\n",
    "nap_model, training_scale, database, mesh_names, cfg = prepare_nap(VERSION, EP)\n",
    "cates = cfg[\"dataset\"][\"cates\"]\n",
    "K = cfg[\"dataset\"][\"max_K\"]\n",
    "DST = f\"../log/test/G/K_{K}_cate_{''.join(cates)}_{VERSION}_{EP}\"\n",
    "DST_viz = f\"../log/test/Viz/K_{K}_cate_{''.join(cates)}_{VERSION}_{EP}\"\n",
    "DST_retrieval = f\"../log/test/G/K_{K}_cate_{''.join(cates)}_{VERSION}_{EP}_retrieval\"\n",
    "DST_retrieval_viz = f\"../log/test/Viz/K_{K}_cate_{''.join(cates)}_{VERSION}_{EP}_retrieval\"\n",
    "GT_MESH_ROOT =  \"../data/partnet_mobility_graph_mesh\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 449\n",
    "# N = 2\n",
    "gen_V, gen_E, noise_V, noise_E = gen(nap_model, *training_scale, N=N)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Standard saving\n",
    "\n",
    "This is a little slow because it extract the mesh with MC as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from save_viz_utils import save\n",
    "\n",
    "save(\n",
    "    gen_V,\n",
    "    gen_E,\n",
    "    mesh_extraction_fn=nap_model.generate_mesh,\n",
    "    dst=DST,\n",
    "    dst_retrieval=DST_retrieval,\n",
    "    database=database,\n",
    "    mesh_names=mesh_names,\n",
    "    gt_mesh_dir=GT_MESH_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from save_viz_utils import viz_dir\n",
    "\n",
    "viz_dir(DST, DST_viz, max_viz=40)\n",
    "viz_dir(DST_retrieval, DST_retrieval_viz, max_viz=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flatwhite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
